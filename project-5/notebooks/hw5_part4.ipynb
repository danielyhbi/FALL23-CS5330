{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10fe2ce30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===================================================\n",
    "# initialize run environment as non-function calls\n",
    "# so i don't pass 100000 variables in to a function\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 100\n",
    "n_epochs = 3\n",
    "mnist_global_mean = 0.1307\n",
    "mnist_global_stdev = 0.3081\n",
    "random_seed = 1\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "epochs = 5\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "# ==================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    # channelSize is on the increment\n",
    "    def __init__(self, convoCount, channelSize, dropoutRate, pixelSize):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        # Feature Extraction Stage\n",
    "        self.feature_maps_stack = nn.Sequential()\n",
    "        startChannel = 1\n",
    "        \n",
    "        for count in range(convoCount):\n",
    "            self.feature_maps_stack.append(nn.Conv2d(in_channels=startChannel,\n",
    "                                                         out_channels=channelSize * (count + 1),\n",
    "                                                         kernel_size=5))\n",
    "            pixelSize -= 4\n",
    "            print(pixelSize)\n",
    "            \n",
    "            if count >= 1:\n",
    "                self.feature_maps_stack.append(nn.Dropout2d(p=dropoutRate))\n",
    "                \n",
    "            if count >= 1 and count < 3:\n",
    "                self.feature_maps_stack.append(nn.MaxPool2d(kernel_size=2))\n",
    "                # print(\"Before divide by 2\")\n",
    "                # print(pixelSize)\n",
    "                pixelSize = int(pixelSize / 2)\n",
    "                # print(\"After divide by 2\")\n",
    "                # print(pixelSize)\n",
    "                \n",
    "            self.feature_maps_stack.append(nn.ReLU())\n",
    "            \n",
    "            # reset env\n",
    "            startChannel = channelSize * (count + 1)\n",
    "        \n",
    "        totalNode = pixelSize * pixelSize * startChannel\n",
    "        \n",
    "        # Classification Stage\n",
    "        self.classify_stack = nn.Sequential(\n",
    "            # A flattening operation \n",
    "            nn.Flatten(),\n",
    "            # followed by a fully connected Linear layer with 50 nodes \n",
    "            nn.Linear(totalNode, 50),\n",
    "            # and a ReLU function on the output\n",
    "            nn.ReLU(),\n",
    "            # A final fully connected Linear layer with 10 nodes\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.feature_maps_stack(x)\n",
    "        logits = self.classify_stack(features)\n",
    "        \n",
    "        # and the log_softmax function applied to the output\n",
    "        return nn.functional.log_softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "20\n",
      "6\n",
      "NeuralNetwork(\n",
      "  (feature_maps_stack): Sequential(\n",
      "    (0): Conv2d(1, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(30, 60, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (3): Dropout2d(p=0.5, inplace=False)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(60, 90, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (7): Dropout2d(p=0.5, inplace=False)\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): ReLU()\n",
      "  )\n",
      "  (classify_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=810, out_features=50, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(3, 30, 0.5, 28)\n",
    "\n",
    "# print(model)\n",
    "test = str(model)\n",
    "print(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
